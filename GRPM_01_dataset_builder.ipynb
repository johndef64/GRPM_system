{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPM Dataset Builder 2.0 (LitVar2 Patch)\n",
    "\n",
    "This notebook is designed to retrieve genetic polymorphism data from multiple sources. It uses the LitVar API to extract polymorphisms for each human gene within the LitVar2 database along with all associated PubMed Identifiers (PMIDs). These PMIDs are then employed as queries on PubMed to obtain MEDLINE data (parsed though the 'nbib' package). All collected data are ultimately consolidated into a single CSV file, known as the \"GRPM Dataset\", which serves as the primary source against which MeSH term queries can be launched to retrieve genes and polymorphisms associated with specific contexts.  \n",
    "\n",
    "**Updates** : \n",
    "\n",
    "The GRPM Dataset available on Zenodo is a snapshot of [LitVar1](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/LitVar/help.html). LitVar1 is now <u>**deprecated**</u> and has been fully replaced by [LitVar2](https://www.ncbi.nlm.nih.gov/research/litvar2/). This module \n",
    "([Dataset Builder](https://github.com/johndef64/GRPM_system/blob/main/GRPM_01_dataset_builder.ipynb)) has been updated to retrieve data from LitVar2. The subsequent modules in the pipeline remain functional and can be tested using the original version of the GRPM Dataset available on Zenodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T10:08:27.549760300Z",
     "start_time": "2024-03-14T10:08:27.516843900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: G:\\Altri computer\\Horizon\\horizon_workspace\\projects\\bioinformatics\\semantics\\GRPM\\GRPM_dev\n"
     ]
    }
   ],
   "source": [
    "#Only for Google Colab\n",
    "import ast\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# @markdown Run in Colab virtual machine by default\n",
    "\n",
    "# @markdown to run in google drive set:\n",
    "import_mydrive = False #@param {type:\"boolean\"}\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install nbib\n",
    "    !pip install biopython\n",
    "\n",
    "    if import_mydrive:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        if os.path.exists('/content/drive/MyDrive/grpm_system/'):\n",
    "            %cd /content/drive/MyDrive/grpm_system/\n",
    "        else:\n",
    "            %mkdir /content/drive/MyDrive/grpm_system/\n",
    "            %cd /content/drive/MyDrive/grpm_system/\n",
    "    else:\n",
    "        if os.path.exists('/content/grpm_system/'):\n",
    "            %cd /content/grpm_system/\n",
    "        else:\n",
    "            %mkdir /content/grpm_system/\n",
    "            %cd /content/grpm_system/\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get required data from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T10:08:44.511914900Z",
     "start_time": "2024-03-14T10:08:41.231007900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP file 'human_genes_repo.zip' extracted to 'G:\\Altri computer\\Horizon\\horizon_workspace\\projects\\bioinformatics\\semantics\\GRPM\\GRPM_dev' successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get Required datasets from Zenodo Repository\n",
    "#https://zenodo.org/record/8205724  DOI: 10.5281/zenodo.8205724\n",
    "\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "def get_and_extract(file, dir = os.getcwd()):\n",
    "    url = \"https://zenodo.org/record/8205724/files/\"+file+\".zip?download=1\"\n",
    "    zip_file_name = file+\".zip\"\n",
    "    extracted_folder_name = dir\n",
    "\n",
    "    # Download the ZIP file\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Extract the ZIP contents\n",
    "        with io.BytesIO(response.content) as zip_buffer:\n",
    "            with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extracted_folder_name)\n",
    "        print(f\"ZIP file '{zip_file_name}' extracted to '{extracted_folder_name}' successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file.\")\n",
    "\n",
    "if not os.path.exists('human_geness_repo'):\n",
    "    get_and_extract('human_genes_repo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Requirements and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:45:41.908168300Z",
     "start_time": "2024-03-15T10:45:41.807706400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The module 'nbib' is already installed.\n",
      "The module 'requests' is already installed.\n"
     ]
    }
   ],
   "source": [
    "#@Import Requirements and Functions\n",
    "import importlib\n",
    "\n",
    "def simple_bool(message):\n",
    "    choose = input(message+\" (y/n): \").lower()\n",
    "    your_bool = choose in [\"y\", \"yes\"]\n",
    "    return your_bool\n",
    "\n",
    "def check_and_install_module(module_name):\n",
    "    try:\n",
    "        # Check if the module is already installed\n",
    "        importlib.import_module(module_name)\n",
    "        print(f\"The module '{module_name}' is already installed.\")\n",
    "    except ImportError:\n",
    "        # If the module is not installed, try installing it\n",
    "        x = simple_bool(\n",
    "            \"\\n\" + module_name + \"  module is not installed.\\nwould you like to install it?\")\n",
    "        if x:\n",
    "            import subprocess\n",
    "            subprocess.check_call([\"pip\", \"install\", module_name])\n",
    "            print(f\"The module '{module_name}' was installed correctly.\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "check_and_install_module('nbib')\n",
    "check_and_install_module('requests')\n",
    "\n",
    "#Import Modules\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import nbib\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "from Bio import Entrez\n",
    "import time\n",
    "\n",
    "Entrez.email = \"your_email@example.com\"\n",
    "\n",
    "request_counter = 0\n",
    "gene_counter = 0\n",
    "\n",
    "# Job Functions \n",
    "def transform_string(string):\n",
    "    string = string.replace(\"\\n\",\", \")\n",
    "    string = string.replace(\"\\'\",\"\\\"\")\n",
    "    string = string.replace('\\\"\\\"', '\\\"')\n",
    "    string = string.replace('p.\\\"','p.')\n",
    "    string = string.replace('c.\\\"','c.')\n",
    "    string = string.replace('g.\\\"','g.')\n",
    "    string = string.replace('\\\">','>')\n",
    "    string = string.replace('.C\\\"204','.C204') #<= if stucked, look for bugs like this into text\n",
    "    return string\n",
    "\n",
    "def query_build(pmid_list):\n",
    "    query = \"+OR+\".join(pmid_list)\n",
    "    return query\n",
    "\n",
    "def build_pubmed_query(pmid_l, limit = 1300):\n",
    "    query = []\n",
    "\n",
    "    if len(pmid_l)<=limit:\n",
    "        pmid_l01 = pmid_l\n",
    "        query = [query_build(pmid_l01)]\n",
    "\n",
    "    if limit<len(pmid_l)<=limit*2:\n",
    "        j = len(pmid_l)//2\n",
    "        pmid_l01 = pmid_l[:j]\n",
    "        pmid_l02 = pmid_l[j:]\n",
    "        query = [query_build(pmid_l01),\n",
    "                 query_build(pmid_l02)]\n",
    "\n",
    "    if limit*2<len(pmid_l)<=limit*3:\n",
    "        j = len(pmid_l)//3\n",
    "        pmid_l01 = pmid_l[:j]\n",
    "        pmid_l02 = pmid_l[j:j*2]\n",
    "        pmid_l03 = pmid_l[j*2:]\n",
    "        query = [query_build(pmid_l01),\n",
    "                 query_build(pmid_l02),\n",
    "                 query_build(pmid_l03)]\n",
    "\n",
    "    if limit*3<len(pmid_l)<=limit*4:\n",
    "        j = len(pmid_l)//4\n",
    "        pmid_l01 = pmid_l[:j]\n",
    "        pmid_l02 = pmid_l[j:j*2]\n",
    "        pmid_l03 = pmid_l[j*2:j*3]\n",
    "        pmid_l04 = pmid_l[j*3:]\n",
    "        query = [query_build(pmid_l01),\n",
    "                 query_build(pmid_l02),\n",
    "                 query_build(pmid_l03),\n",
    "                 query_build(pmid_l04)]\n",
    "\n",
    "    if limit*4<len(pmid_l)<=limit*5:\n",
    "        j = len(pmid_l)//5\n",
    "        pmid_l01 = pmid_l[:j]\n",
    "        pmid_l02 = pmid_l[j:j*2]\n",
    "        pmid_l03 = pmid_l[j*2:j*3]\n",
    "        pmid_l04 = pmid_l[j*3:j*4]\n",
    "        pmid_l05 = pmid_l[j*4:]\n",
    "        query = [query_build(pmid_l01),\n",
    "                 query_build(pmid_l02),\n",
    "                 query_build(pmid_l03),\n",
    "                 query_build(pmid_l04),\n",
    "                 query_build(pmid_l05)]\n",
    "\n",
    "    if limit*5<len(pmid_l)<=limit*6:\n",
    "        j = len(pmid_l)//6\n",
    "        pmid_l01 = pmid_l[:j]\n",
    "        pmid_l02 = pmid_l[j:j*2]\n",
    "        pmid_l03 = pmid_l[j*2:j*3]\n",
    "        pmid_l04 = pmid_l[j*3:j*4]\n",
    "        pmid_l05 = pmid_l[j*4:j*5]\n",
    "        pmid_l06 = pmid_l[j*5:]\n",
    "        query = [query_build(pmid_l01),\n",
    "                 query_build(pmid_l02),\n",
    "                 query_build(pmid_l03),\n",
    "                 query_build(pmid_l04),\n",
    "                 query_build(pmid_l05),\n",
    "                 query_build(pmid_l06)]\n",
    "\n",
    "    if limit*6<len(pmid_l)<=limit*7:\n",
    "        j = len(pmid_l)//7\n",
    "        pmid_l01 = pmid_l[:j]\n",
    "        pmid_l02 = pmid_l[j:j*2]\n",
    "        pmid_l03 = pmid_l[j*2:j*3]\n",
    "        pmid_l04 = pmid_l[j*3:j*4]\n",
    "        pmid_l05 = pmid_l[j*4:j*5]\n",
    "        pmid_l06 = pmid_l[j*5:j*6]\n",
    "        pmid_l07 = pmid_l[j*6:]\n",
    "        query = [query_build(pmid_l01),\n",
    "                 query_build(pmid_l02),\n",
    "                 query_build(pmid_l03),\n",
    "                 query_build(pmid_l04),\n",
    "                 query_build(pmid_l05),\n",
    "                 query_build(pmid_l06),\n",
    "                 query_build(pmid_l07)]\n",
    "    return query\n",
    "\n",
    "\n",
    "def plot_data(df_count_sort, timestamp):\n",
    "    x1 = df_count_sort['mesh'].head(30)\n",
    "    y1 = df_count_sort['pmid-unique'].head(30)\n",
    "    plt.figure(figsize=(5, 8))\n",
    "    plt.title('Scatter Plot: '+gene+' pmid-mesh (total)', loc='center',pad=10)\n",
    "    plt.scatter(y1, x1)\n",
    "    plt.gca().invert_yaxis()\n",
    "    #plt.yticks(rotation=90)\n",
    "    plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    plt.savefig(db_path+'/'+gene+'_mesh_plot_'+timestamp+'_total.png',dpi=120, bbox_inches = \"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def get_studytype_data(ref):\n",
    "    dfbib = pd.DataFrame(ref)\n",
    "    dfbib.pubmed_id = dfbib.pubmed_id.astype('str')\n",
    "    if 'publication_types' in dfbib.columns and len(dfbib['publication_types'])>1:\n",
    "        dfbib_studyty = dfbib[['pubmed_id','publication_types']].dropna().reset_index(drop=True)\n",
    "\n",
    "        #PMID-Studytype table build:\n",
    "        df_studytype = []\n",
    "        for i in range(len(dfbib_studyty)):\n",
    "            for studytype in dfbib_studyty['publication_types'][i]:\n",
    "                out = dfbib_studyty['pubmed_id'][i], studytype\n",
    "                df_studytype.append(out)\n",
    "        STUDYT = pd.DataFrame(df_studytype).rename(columns={0: 'pmids',1:'study_type'})\n",
    "        mask_st = STUDYT['study_type'].str.contains('Research Support|Journal Article')\n",
    "        STUDYTless = STUDYT[~mask_st].reset_index(drop=True)\n",
    "\n",
    "        mask_lessing = STUDYT['pmids'].isin(STUDYTless['pmids'])\n",
    "        STUDYTdiff = STUDYT[~mask_lessing].reset_index(drop=True)\n",
    "        STUDYTdiff['study_type2'] = 'Unknown'\n",
    "        STUDYTdiff = STUDYTdiff[['pmids','study_type2']].rename(columns={'study_type2':'study_type'}).drop_duplicates().reset_index(drop=True)\n",
    "        STUDYTconcat = pd.concat([STUDYTless, STUDYTdiff], ignore_index=True)\n",
    "\n",
    "        STUDYTconcat.to_csv(db_path+'/'+gene+'_lit1pmid_studytype.csv')\n",
    "    else:\n",
    "        print(gene+' no publication_types in nbib')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole genome forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:31.504293900Z",
     "start_time": "2024-03-15T10:00:31.292564900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast:\n",
      "max genes/day=  2352\n",
      "for 19383 genes:\n",
      "    request counter = 82377.75 requests\n",
      "    whole genome runtime = 34.24 hours\n",
      "    whole genome runtime overnight = 40.17\n",
      "    db table size 7695.05 MB\n"
     ]
    }
   ],
   "source": [
    "#Statistics based on 150 random genes:\n",
    "time_sleep = 0.4\n",
    "runtime_gene = 6.36 #sec/gene\n",
    "genes_hour = 566 #genes/hour\n",
    "request_counter_gene = 4.25 #request/gene (with base sleep (0.4))\n",
    "sleep_request_base = 0.4 #time sleep each request\n",
    "sleep_request_overnight_plus = 1.1 # for an overnight job\n",
    "\n",
    "print('Forecast:')\n",
    "max_genes = int(10000/request_counter_gene)\n",
    "table_size_db_gene = 0.496 #MB\n",
    "table_size_gene = 0.397 #MB\n",
    "png_size_db_gene = 0.47 #KB\n",
    "\n",
    "#Forecast:\n",
    "genes = pd.read_csv('human_genes_repo/H_GENES_proteincoding_genes.csv')\n",
    "ngenes = len(genes)#gene_range\n",
    "nruntime = ngenes * runtime_gene\n",
    "#print('runtime, '+str(ngenes), nruntime)\n",
    "nrequest_counter = ngenes * request_counter_gene\n",
    "\n",
    "tempo_ore = round(nruntime/3600, 2)\n",
    "tempo_ore_overnight = round((nruntime+(sleep_request_overnight_plus*ngenes))/3600, 2)\n",
    "\n",
    "print('max genes/day= ',max_genes)\n",
    "print('for',str(int(ngenes)),'genes:')\n",
    "print('    request counter =', nrequest_counter,'requests')\n",
    "print('    whole genome runtime =', tempo_ore,'hours')\n",
    "print('    whole genome runtime overnight =', tempo_ore_overnight)\n",
    "\n",
    "db_table_size = ngenes * table_size_gene\n",
    "print('    db table size', round(db_table_size,2),'MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Human Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:00:33.914048800Z",
     "start_time": "2024-03-15T10:00:33.689083100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protein_coding_genes 19318 \n",
      "IG_TR_genes 641 \n",
      "RNA_genes 11452 \n",
      "pseudo_genes 9866 \n",
      "misc_genes 22\n",
      "\n",
      "recommended job lenght for pcg: 1073\n"
     ]
    }
   ],
   "source": [
    "# Load Human Gene list ---------------------------------\n",
    "protein_coding_genes = pd.read_csv('human_genes_repo/H_GENES_proteincoding_genes.csv')\n",
    "IG_TR_genes          = pd.read_csv('human_genes_repo/H_GENES_IGTR_genes.csv')\n",
    "RNA_genes            = pd.read_csv('human_genes_repo/H_GENES_RNA_genes.csv')\n",
    "pseudo_genes         = pd.read_csv('human_genes_repo/H_GENES_pseudo_genes.csv')\n",
    "misc_genes           = pd.read_csv('human_genes_repo/H_GENES_misc_genes.csv')\n",
    "\n",
    "# create gene lists:\n",
    "protein_coding_genes_list = protein_coding_genes['Gene name'].dropna().tolist()\n",
    "rna_genes_list = RNA_genes['Gene name'].dropna().tolist()\n",
    "pseudo_genes_list = pseudo_genes['Gene name'].dropna().tolist()\n",
    "\n",
    "\n",
    "# Split job packages:----------------------------------\n",
    "\n",
    "# (1) protein coding genes:\n",
    "gene_range = int(len(protein_coding_genes_list)/18)\n",
    "genes = [protein_coding_genes_list[i * gene_range : (i + 1) * gene_range] for i in range(0, 18)]\n",
    "pcg_chunks = genes[:18]\n",
    "\n",
    "# (2) RNA genes:\n",
    "rna_gene_range = int(len(rna_genes_list)/5)\n",
    "genes = [rna_genes_list[i * rna_gene_range : (i + 1) * rna_gene_range] for i in range(0, 8)]\n",
    "rna_chunks = genes[:5]\n",
    "\n",
    "# (3) pseudo genes:\n",
    "pseudo_gene_range = int(len(pseudo_genes_list)/2)\n",
    "genes = [rna_genes_list[i * pseudo_gene_range : (i + 1) * pseudo_gene_range] for i in range(0, 8)]\n",
    "pseudo_chunks = genes[:2]\n",
    "\n",
    "print('protein_coding_genes',len(protein_coding_genes['Gene name'].dropna()),\n",
    "      '\\nIG_TR_genes',len(IG_TR_genes['Gene name'].dropna()),\n",
    "      '\\nRNA_genes',len(RNA_genes['Gene name'].dropna()),\n",
    "      '\\npseudo_genes',len(pseudo_genes['Gene name'].dropna()),\n",
    "      '\\nmisc_genes',len(misc_genes['Gene name'].dropna()))\n",
    "\n",
    "print('\\nrecommended job lenght for pcg:',int(len(protein_coding_genes_list)/18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set options and import building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:17:04.912487700Z",
     "start_time": "2024-03-15T10:17:04.851907700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time load 0:00:00.043998\n",
      "complete_df gene count: 9 on 19318\n",
      "\n",
      "grpm_table_output.csv size 0.027 MB\n",
      "complete_nbibtable.csv size 0.252 MB\n",
      "memory_usage_complete_df 0.023\n",
      "memory_usage_complete_nbib_df 0.009\n"
     ]
    }
   ],
   "source": [
    "# set db:--------------------------------\n",
    "db_tag = 'pcg_2024_lit2'\n",
    "    # 'pcg'    = protein coding genes = grpm_db\n",
    "    # 'rna'    = rna genes            = grpm_db_rna\n",
    "    # 'pseudo' = pseudogenes          = grpm_db_pseudo\n",
    "\n",
    "db_name = 'grpm_db_'+db_tag\n",
    "db_path = 'grpm_dataset/'+db_name\n",
    "\n",
    "if not os.path.exists(db_path):\n",
    "    os.makedirs(db_path)\n",
    "#------------------------------------------------\n",
    "\n",
    "\n",
    "#import checkpoint datasets:\n",
    "time_a = datetime.now()\n",
    "if os.path.isfile(db_path+'/grpm_table_output.csv'):\n",
    "    complete_df = pd.read_csv(db_path+'/grpm_table_output.csv',index_col=0)\n",
    "    restart = True\n",
    "else:\n",
    "    complete_df = pd.DataFrame()\n",
    "    restart = False\n",
    "\n",
    "if os.path.isfile(db_path+'/complete_nbibtable.csv'):\n",
    "    complete_nbibtable = pd.read_csv(db_path+'/complete_nbibtable.csv',index_col=0)\n",
    "else:\n",
    "    complete_nbibtable = pd.DataFrame()\n",
    "time_b = datetime.now()\n",
    "\n",
    "print('time load',time_b-time_a)\n",
    "\n",
    "## check saved data:\n",
    "if os.path.isfile(db_path+'/grpm_table_output.csv'):\n",
    "    gene_db_count =  complete_df.gene.nunique()\n",
    "    print('complete_df gene count:',gene_db_count,'on', len(protein_coding_genes_list))\n",
    "    if gene_db_count >= 15519:\n",
    "        print('grpm db already contains all available genes on litvar1')\n",
    "\n",
    "    print('\\ngrpm_table_output.csv size'  ,round(os.path.getsize(db_path+'/grpm_table_output.csv')/(1024*1024),3),'MB')\n",
    "    print('complete_nbibtable.csv size',round(os.path.getsize(db_path+'/complete_nbibtable.csv')/(1024*1024),3),'MB')\n",
    "    print('memory_usage_complete_df'     ,round(complete_df.memory_usage().sum()/(1024*1024),3))\n",
    "    print('memory_usage_complete_nbib_df',round(complete_nbibtable.memory_usage().sum()/(1024*1024),3))\n",
    "else:\n",
    "    print('empty dataset')\n",
    "    print('empty dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set gene-range for this job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:17:14.747484400Z",
     "start_time": "2024-03-15T10:17:08.822308900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the gene list ----------------\n",
    "\n",
    "#1. Set gene-range [whole genome build]\n",
    "    # pcg_chunks    [0:17]\n",
    "    # rna_chunks    [0:4]\n",
    "    # pseudo_chunks [0:1]\n",
    "gene_chunk = pcg_chunks[0]\n",
    "\n",
    "# run a sample?\n",
    "run_sample = simple_bool('Do you want to run a chunk sample for testing?')\n",
    "if run_sample:\n",
    "    sample_size = int(input('sample size? \\nnum:'))\n",
    "\n",
    "\n",
    "#2. place here your custom gene list [custom build]\n",
    "if not run_sample:\n",
    "    custom_genes = ['APOA1', 'FFC1', 'ERH', 'USP53']\n",
    "    custom_list = simple_bool('Do you want to run the custom gene list?')\n",
    "else:\n",
    "    custom_list = False\n",
    "\n",
    "#if stucked, store skipped_genes and run custom list later:\n",
    "skipped_genes =  []\n",
    "\n",
    "# Set save interval checkpoint frequency\n",
    "checkpoint = 5  #genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:46:15.869920500Z",
     "start_time": "2024-03-15T10:45:49.337531700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start at  2024-03-15 11:45:49.383531\n",
      "KRTAP4-8_runtime: 0:00:05.418950\n",
      "CCL3_runtime: 0:00:04.962459\n",
      "TAS2R50_runtime: 0:00:04.964937\n",
      "MT-ND3_runtime: 0:00:05.391834\n",
      "SIRPG_runtime: 0:00:05.396164\n",
      "gene batch: 5\n",
      "time batch: 0:00:26\n",
      "runtime/gene: 0:00:05.296127\n",
      "request_counter: 10  (limit: 10.000/day)\n",
      "requests/gene: 2.0\n",
      "2024-03-15 11:46:15.864166\n"
     ]
    }
   ],
   "source": [
    "# set options:--------------------------------\n",
    "save_plot           = True\n",
    "save_studytype_data = False\n",
    "save_accessory_data = False\n",
    "\n",
    "import ast\n",
    "# Run Job -------------------------\n",
    "\n",
    "if run_sample:\n",
    "    genes = pd.Series(gene_chunk).sample(sample_size).reset_index(drop=True)\n",
    "    genes = genes.to_list()\n",
    "    restart = False\n",
    "else:\n",
    "    genes = pd.Series(gene_chunk)\n",
    "    genes = genes.to_list()\n",
    "\n",
    "if restart:\n",
    "    restart_from = complete_df.gene.nunique()\n",
    "    gene_start = restart_from\n",
    "    print('search restarted from '+str(restart_from))\n",
    "else:\n",
    "    gene_start = 0\n",
    "\n",
    "if custom_list:\n",
    "    genes = custom_genes\n",
    "    gene_start = 0\n",
    "\n",
    "#=========================================================================\n",
    "\n",
    "\n",
    "#=========================================================================\n",
    "time_start = datetime.now()\n",
    "print('Start at ',time_start)\n",
    "\n",
    "# get gene data\n",
    "for gene in genes[gene_start:]:\n",
    "\n",
    "    #LitVar2 \"Variants for Gene\" API request\n",
    "    if request_counter > 9950:\n",
    "        print('Request limit reached. Wait \\'till tomorrow!')\n",
    "        pass\n",
    "    time_alpha = datetime.now()\n",
    "    url = \"https://www.ncbi.nlm.nih.gov/research/litvar2-api/variant/search/gene/\" + gene\n",
    "    response = (rq.get(url)).text\n",
    "\n",
    "    # parsing output in JSON\n",
    "    \n",
    "    data= \"[\" + transform_string(response) + \"]\"\n",
    "    \n",
    "    #Create Dataframe\n",
    "    df = pd.read_json(StringIO(data))\n",
    "    if 'rsid' in df.columns and len(df.rsid)>1:\n",
    "        # creare un df senza i clingen.\n",
    "        dfb = df[['_id','pmids_count','rsid']]\n",
    "        dfa = dfb[~dfb['_id'].str.contains('@CA')].drop_duplicates().reset_index(drop=True)\n",
    "        dfn = dfa.dropna(subset=['rsid'])\n",
    "\n",
    "        #Statistics\n",
    "        #handle = Entrez.esearch(db=\"snp\", term=gene)\n",
    "        #record = Entrez.read(handle)\n",
    "        #request_counter += 1\n",
    "\n",
    "        NCBI_dbSNP = 'na' #record[\"Count\"]\n",
    "        lit2_variant = len(dfa['_id'].drop_duplicates())\n",
    "        lit2_variant_norsid = len(dfa.loc[df['rsid'].isna()])\n",
    "        lit2_rsid = len(dfn.rsid.drop_duplicates())\n",
    "\n",
    "        # remove rs with pmid_count = 1\n",
    "        df2 = dfn.loc[df.pmids_count !=1]#.reset_index(drop=True)\n",
    "        lit2_rsid_f = len(df2)\n",
    "\n",
    "        # accessory data\n",
    "        dfsort = df.sort_values(by='pmids_count',ascending=False).reset_index(drop=True)\n",
    "        df2sort = df2.sort_values(by='pmids_count',ascending=False).reset_index(drop=True)\n",
    "      \n",
    "\n",
    "        for rsid in df2.rsid[0:1]:\n",
    "            url=\"https://www.ncbi.nlm.nih.gov/research/litvar2-api/variant/get/litvar@\"+rsid+\"%23%23/publications\"\n",
    "            response = (rq.get(url)).text\n",
    "            response_dict = ast.literal_eval(response)\n",
    "            #rspost = pd.DataFrame(response_dict)\n",
    "            rspost = pd.DataFrame({key: pd.Series(value) for key, value in response_dict.items()})\n",
    "            \n",
    "            #Display-------------------------------------------------------\n",
    "            dfrspost = pd.DataFrame(rspost)\n",
    "            if 'pmids' in dfrspost.columns and len(dfrspost.pmids_count)>1:\n",
    "            #if 'rsid' in dfrspost.columns and len(dfrspost.rsid)>1:\n",
    "                #lit1_rsid = len(dfrspost.rsid)\n",
    "                lit1_rsid = 0\n",
    "                #lit2_rsid = len(df)\n",
    "    \n",
    "                # Creating the simple list [rsid-pmid]========================\n",
    "    \n",
    "                rsidpmid = dfrspost[['pmids']].copy()\n",
    "                rsidpmid['rsid'] = str(rsid)\n",
    "                rsidpmid['pmids'] = rsidpmid['pmids'].astype('str')\n",
    "                \n",
    "                #report data:\n",
    "                lit1_rsid_pmid = len(rsidpmid)\n",
    "                lit1_pmid = len(rsidpmid.drop_duplicates(subset='pmids'))\n",
    "    \n",
    "    \n",
    "                ####[MODULE: groupby.describe]\n",
    "                # applicare groupby ad rsidpmid per avere tabella pmid count\n",
    "                rsidpmidcount = rsidpmid.groupby('rsid').describe().reset_index()\n",
    "                rsidpmidcount.columns = rsidpmidcount.columns.to_flat_index()\n",
    "            \n",
    "\n",
    "                #replace column names\n",
    "                new_column_names = ['rsid', 'pmid_count', 'pmid_unique','pmid_top','pmid_freq']\n",
    "                rsidpmidcount.columns = new_column_names\n",
    "                rsidpmidcountf = rsidpmidcount[['rsid','pmid_unique']]\n",
    "    \n",
    "                #report data:-------------------------------------------------------------\n",
    "                lit1_rsid_f = len(rsidpmidcountf[rsidpmidcountf.pmid_unique!=1])\n",
    "                lit1_rsid_m = len(rsidpmidcountf[rsidpmidcountf.pmid_unique==1])\n",
    "    \n",
    "                rsidpmidcountfsort = rsidpmidcountf.sort_values('pmid_unique',ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "                #Filter pmid for rsid with pmid>1------------------------------------------\n",
    "                outless = rsidpmidcountfsort[rsidpmidcountfsort.pmid_unique>1]\n",
    "                #creare una mask isin su rsidpmid con outless.rsid\n",
    "                mask = rsidpmid['rsid'].isin(outless.rsid)\n",
    "                rsidpmidless = rsidpmid[mask]\n",
    "                lit1_pmid_f = len(rsidpmidless.pmids.drop_duplicates())\n",
    "    \n",
    "    \n",
    "                # PubMed query Build:=====================================================\n",
    "                ### two input alternatives (total LitVar1 and LitVar>1)\n",
    "                #Total\n",
    "                pmid_l = rsidpmid.pmids.drop_duplicates().tolist()\n",
    "\n",
    "                ##Define list of queries for PubMed:\n",
    "                query = build_pubmed_query(pmid_l, limit = 1300)\n",
    "                \n",
    "    \n",
    "                # Merging requests for the queries\n",
    "                ### carefull: high runtime\n",
    "    \n",
    "                time1 = datetime.now()\n",
    "                pages = ((len(pmid_l)//200)+1)+1\n",
    "                if len(pmid_l) % 200 == 0:\n",
    "                    pages = pages -1\n",
    "                fullnbib = str()\n",
    "                for d in query:\n",
    "                    for i in range(1,pages):\n",
    "                        page = str(i)\n",
    "                        url = 'https://pubmed.ncbi.nlm.nih.gov/?term=' + d + '&format=pubmed&size=200&page='+ page\n",
    "                        output = rq.get(url)\n",
    "                        html = output.text\n",
    "                        soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "                        for script in soup([\"script\", \"style\"]):\n",
    "                            script.extract()\n",
    "                        text = soup.get_text()\n",
    "                        postString = text.split(\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\",2)[2]\n",
    "                        nbib01 = postString.replace('\\n\\n','')\n",
    "                        fullnbib += nbib01\n",
    "                        request_counter += pages\n",
    "                        time.sleep(1.5)\n",
    "    \n",
    "                time2 = datetime.now()\n",
    "                timestamp = time2.strftime('%Y%m%d%H%M%S')\n",
    "                #^print('finish at:', datetime.now())\n",
    "                runtime = time2-time1\n",
    "                duration = str(runtime).split('.')[0]\n",
    "                hours, minutes, seconds = duration.split(':')\n",
    "                compact_duration = '{}:{}:{}'.format(hours, minutes, seconds)\n",
    "    \n",
    "    \n",
    "                # nbib parsing:\n",
    "                timea = datetime.now()\n",
    "                ref = nbib.read(fullnbib)\n",
    "                dfbib = pd.DataFrame(ref)\n",
    "                if 'descriptors' in dfbib.columns and len(dfbib['descriptors'])>1:\n",
    "                    dfbibdes = dfbib[['pubmed_id','descriptors']].dropna().reset_index(drop=True)\n",
    "                    nbib_objects = len(dfbib)\n",
    "                    nbib_objects_withdescriptors = len(dfbibdes)\n",
    "                    #print('nibib objects:',nbib_objects)\n",
    "                    #print('nibib objects with descriptors:',len(dfbibdes))\n",
    "                    timeb = datetime.now()\n",
    "                    #print('runtime:', timeb-timea)\n",
    "    \n",
    "                    #Statistics:\n",
    "                    pubmed_pmid_query = len(pmid_l)\n",
    "                    pubmed_pmid_nbib = len(dfbib.pubmed_id.drop_duplicates())\n",
    "                    pubmed_pmid_nbib_yesmesh = len(dfbibdes.pubmed_id.drop_duplicates())\n",
    "                    pubmed_pmid_nbib_nomesh = len(dfbib.pubmed_id.drop_duplicates())-len(dfbibdes.pubmed_id.drop_duplicates())\n",
    "    \n",
    "                    # refine MESH\n",
    "                    dfr = []\n",
    "                    for i in range(len(dfbibdes)):\n",
    "                        for mesh in dfbibdes['descriptors'][i]:\n",
    "                            out = dfbibdes['pubmed_id'][i], mesh\n",
    "                            dfr.append(out)\n",
    "                    MESH = pd.DataFrame(dfr).rename(columns={0: 'pmids',1:'mesh'})\n",
    "    \n",
    "                    # dataframe parsing splitting three fields\n",
    "                    MESHsplit =[]\n",
    "                    for i in range(len(MESH)):\n",
    "                        mg = MESH.mesh[i].get('descriptor')\n",
    "                        mg2 = MESH.mesh[i].get('qualifier')\n",
    "                        mg3 = MESH.mesh[i].get('major')\n",
    "                        mgg = MESH.pmids[i], mg, mg2, mg3\n",
    "                        MESHsplit.append(mgg)\n",
    "    \n",
    "                    dfmesh = pd.DataFrame(MESHsplit).rename(columns={0: 'pmids',1:'mesh',2:'qualifier',3:'major'}).drop_duplicates()\n",
    "    \n",
    "                    #statistics\n",
    "                    pubmed_pmidmesh = len(dfmesh[['pmids','mesh']].drop_duplicates())\n",
    "                    pubmed_mesh_qualifier_major = len(MESH.mesh.drop_duplicates())\n",
    "                    pubmed_mesh = len(dfmesh.mesh.drop_duplicates())\n",
    "    \n",
    "                    pmidmesh = dfmesh[['pmids','mesh']].drop_duplicates()\n",
    "                    pmidmesh['pmids'] = pmidmesh['pmids'].astype(str) #convert pmid type in str\n",
    "    \n",
    "    \n",
    "                    #Analyze enrichment with groupby.describe method-------------------------------\n",
    "                    #Add rsid coulmn con merge\n",
    "                    rspmidmesh_merge = pd.merge(pmidmesh, rsidpmid, on= 'pmids', how='inner').drop_duplicates().reindex(columns=['pmids', 'rsid', 'mesh'])\n",
    "                    #rspmidmesh_merge['pmids'] = rspmidmesh_merge['pmids'].astype(str)\n",
    "    \n",
    "                    ### groupby.describe analysis by mesh\n",
    "                    meshrspmidmerge_count = rspmidmesh_merge.groupby('mesh').describe().reset_index()\n",
    "                    meshrspmidmerge_count.columns = meshrspmidmerge_count.columns.to_flat_index()\n",
    "                    #to handle generate df.groupby.describe, convert Multicolumn to single column\n",
    "                    #https://datascientyst.com/flatten-multiindex-in-pandas/\n",
    "                    new_column_names = ['mesh', 'pmid-count', 'pmid-unique','pmid-top','pmid-freq','rsid-count', 'rsid-unique','rsid-top','rsid-freq']\n",
    "                    meshrspmidmerge_count.columns = new_column_names\n",
    "    \n",
    "                    meshrspmidmerge_count_short = meshrspmidmerge_count[['mesh','pmid-unique','rsid-unique']]\n",
    "                    #pmidmeshintmerge2meshlesssort = pmidmeshintmerge2meshless.sort_values(by='pmid-unique',ascending=False).reset_index(drop=True)\n",
    "    \n",
    "                    # add frequency\n",
    "                    totalpmid_count = len(pmidmesh.pmids.drop_duplicates())\n",
    "                    meshrspmidmerge_count_short_freq = meshrspmidmerge_count_short.copy()\n",
    "                    meshb_frq = meshrspmidmerge_count_short_freq.loc[:,'pmid-unique'].astype(float)/totalpmid_count\n",
    "                    meshrspmidmerge_count_short_freq.loc[:,'mesh frequency'] = round(meshb_frq,3)#*100\n",
    "                    meshrspmidmerge_count_short_freq_sort = meshrspmidmerge_count_short_freq.sort_values(by='pmid-unique',ascending=False).reset_index(drop=True)\n",
    "    \n",
    "                    top10mesh_all = meshrspmidmerge_count_short_freq_sort['mesh'][:10].tolist()\n",
    "                    #display(meshrspmidmerge_count_short_freq_sort.head(20))\n",
    "    \n",
    "                    ### groupby.describe analysis by rsid------------------\n",
    "                    rspmidmeshmerge_count = rspmidmesh_merge.groupby('rsid').describe().reset_index()\n",
    "                    rspmidmeshmerge_count.columns = rspmidmeshmerge_count.columns.to_flat_index()\n",
    "                    new_column_names = ['rsid', 'pmid-count', 'pmid-unique','pmid-top','pmid-freq','mesh-count', 'mesh-unique','mesh-top','mesh-freq']\n",
    "                    rspmidmeshmerge_count.columns = new_column_names\n",
    "    \n",
    "                    rsid_pmid10 = len(rspmidmeshmerge_count[rspmidmeshmerge_count['pmid-unique']>10])\n",
    "                    rsid_pmid50 = len(rspmidmeshmerge_count[rspmidmeshmerge_count['pmid-unique']>50])\n",
    "                    rsid_pmid100 = len(rspmidmeshmerge_count[rspmidmeshmerge_count['pmid-unique']>100])\n",
    "    \n",
    "                    rspmidmeshmerge_count_short = rspmidmeshmerge_count[['rsid','pmid-unique','mesh-unique']]\n",
    "                    rspmidmeshmerge_count_short_sort = rspmidmeshmerge_count_short.sort_values(by='pmid-unique', ascending= False).reset_index(drop=True)\n",
    "                    top10rsid_all = rspmidmeshmerge_count_short_sort['rsid'].iloc[:10].tolist()\n",
    "\n",
    "                    # create a scatter plot-----------------------------------------\n",
    "                    if save_plot:\n",
    "                        plot_data(meshrspmidmerge_count_short_freq_sort, timestamp)\n",
    " \n",
    "                    # GET STUDY TYPE from NBIB----------------------------------------\n",
    "                    if save_studytype_data:\n",
    "                        get_studytype_data(ref)\n",
    "    \n",
    "    #SAVE TABLES-----------------------------------------------------------\n",
    "                    timestamp = time2.strftime('%Y%m%d%H%M%S')\n",
    "                    # save accessory data:\n",
    "                    if save_accessory_data:\n",
    "                        dfsort[[\"_id\",\"rsid\",\"pmids_count\"]].to_csv(db_path+'/'+gene+'_litvar2_variants4gene.csv')\n",
    "                        rsidpmid.to_csv(db_path+'/'+gene+'_litvar1_rsids2pmids.csv') #lit1 [rsid-pmid]\n",
    "                        #rsidpmidcountfsort #lit1 pmid count\n",
    "    \n",
    "                        meshrspmidmerge_count_short_freq_sort.to_csv(db_path+'/'+gene+'_mesh_pmidrsid_count.csv')\n",
    "    \n",
    "                    #complete_df with concat:\n",
    "                    #import gene-rsidpmidmesh and gene-rsidpmid\n",
    "                    dfmesh['pmids'] = dfmesh['pmids'].astype(str)\n",
    "                    rsidpmid['pmids'] = rsidpmid['pmids'].astype(str)\n",
    "    \n",
    "                    # add a rsid-merger to dfmesh\n",
    "                    gene_rsidpmidmesh = pd.merge(rsidpmid, dfmesh, on='pmids')\n",
    "                    gene_rsidpmidmesh['gene'] = gene\n",
    "    \n",
    "                    gene_df = pd.DataFrame(gene_rsidpmidmesh)\n",
    "                    complete_df = pd.concat([complete_df, gene_rsidpmidmesh])\n",
    "    \n",
    "                    #complete_nbibtable with concat:\n",
    "                    dfbib['gene'] = gene\n",
    "                    complete_nbibtable = pd.concat([complete_nbibtable, dfbib])\n",
    "                    #pyperclip.copy(str(dfbib.columns.to_list()))\n",
    "    \n",
    "                    # save checkpoint----------------------\n",
    "                    if genes.index(gene) > 1 and genes.index(gene) % checkpoint == 0:\n",
    "                        complete_df = complete_df.reindex(columns=['gene','rsid', 'pmids', 'mesh', 'qualifier', 'major'])\n",
    "                        complete_df.to_csv(db_path+'/grpm_table_output.csv')\n",
    "    \n",
    "                        complete_nbibtable = complete_nbibtable.reindex(columns=['gene','pubmed_id', 'citation_owner', 'nlm_status', 'last_revision_date', 'electronic_issn', 'linking_issn', 'journal_volume', 'journal_issue', 'publication_date', 'title', 'abstract', 'authors', 'language', 'grants', 'publication_types', 'electronic_publication_date', 'place_of_publication', 'journal_abbreviated', 'journal', 'nlm_journal_id', 'descriptors', 'pmcid', 'keywords', 'conflict_of_interest', 'received_time', 'revised_time', 'accepted_time', 'pubmed_time', 'medline_time', 'entrez_time', 'pii', 'doi', 'publication_status', 'print_issn', 'pages'])\n",
    "                        complete_nbibtable.to_csv(db_path+'/complete_nbibtable.csv')\n",
    "                        print(\"saved checkpoint\")\n",
    "                    else:\n",
    "                        pass\n",
    "    \n",
    "    \n",
    "    #REPORT-----------------------------------------------------------------\n",
    "                    time_omega = datetime.now()\n",
    "                    full_runtime = time_omega - time_alpha\n",
    "                    #^print('total runtime:', full_runtime)\n",
    "                    print(gene + '_runtime:', full_runtime)\n",
    "                    nbib_seconds = runtime.total_seconds()\n",
    "                    total_seconds = full_runtime.total_seconds()\n",
    "                    full_runtime_str = str(full_runtime).split('.')[0]\n",
    "    \n",
    "                    report = {'ncbi_dbsnp': NCBI_dbSNP,\n",
    "                              'lit2_variant': lit2_variant,\n",
    "                              'lit2_variant_norsid': lit2_variant_norsid,\n",
    "                              'lit2_rsid': lit2_rsid,\n",
    "                              'lit2_rsid_plus1': lit2_rsid_f,\n",
    "                              'lit1_rsid': lit1_rsid,\n",
    "                              #'lit1_raw_pmid': lit1_raw_pmid,\n",
    "                              #'lit1_rsid_pmid': lit1_rsid_pmid,\n",
    "                              'lit1_rsid_pmid_plus1': lit1_rsid_f,\n",
    "                              #lit1_rsid_pmid=1': lit1_rsid_m,\n",
    "                              'lit1_pmid': lit1_pmid,\n",
    "                              'lit1_pmid_pmid_plus1': lit1_pmid_f,\n",
    "                              'pubmed_pmid_query': pubmed_pmid_query,\n",
    "                              'nbib_objects': nbib_objects,\n",
    "                              'nbib_objects_withdescriptors': nbib_objects_withdescriptors,\n",
    "                              'pubmed_pmid': pubmed_pmid_nbib,\n",
    "                              'pubmed_pmid_withmesh': pubmed_pmid_nbib_yesmesh,\n",
    "                              #'pubmed_pmid_nomesh':pubmed_pmid_nbib_nomesh,\n",
    "                              'pubmed_pmidmesh': pubmed_pmidmesh,\n",
    "                              'pubmed_mesh_qualifier_major': pubmed_mesh_qualifier_major,\n",
    "                              'pubmed_mesh': pubmed_mesh,\n",
    "                              'rsid_pmid10': rsid_pmid10,\n",
    "                              'rsid_pmid50': rsid_pmid50,\n",
    "                              'rsid_pmid100': rsid_pmid100,\n",
    "                              'top10mesh_all': str(top10mesh_all),\n",
    "                              'top10rsid_all': str(top10rsid_all),\n",
    "                              'pubmed_runtime': duration,\n",
    "                              'total_runtime': full_runtime_str,\n",
    "                              'time_stamp': time2\n",
    "                              }\n",
    "    \n",
    "                    df_report = pd.DataFrame(report, index=[gene]).transpose()\n",
    "    \n",
    "                    # generate fist report.csv\n",
    "                    if os.path.isfile(db_path+'/GRPM_report.csv'):\n",
    "                        dfL = pd.read_csv(db_path+'/GRPM_report.csv', index_col=0)\n",
    "                        dfL = pd.concat([dfL, df_report], axis=1)\n",
    "                        dfL.to_csv(db_path+'/GRPM_report.csv')\n",
    "                    else:\n",
    "                        df_report.to_csv(db_path+'/GRPM_report.csv')  # solo la prima volta\n",
    "    \n",
    "                    #Update gene values\n",
    "                    GRPM_report = pd.read_csv(db_path+'/GRPM_report.csv', index_col=0)\n",
    "                    if gene + '.1' in GRPM_report.columns:\n",
    "                        GRPM_report = GRPM_report.drop(columns=gene)\n",
    "                        GRPM_report = GRPM_report.rename(columns={gene + '.1': gene})\n",
    "                        GRPM_report.to_csv(db_path+'/GRPM_report.csv')\n",
    "                        print(gene,'already in db')\n",
    "    \n",
    "                else:\n",
    "                    print(gene + ' no descriptors in nbib')\n",
    "                    time.sleep(0.8)\n",
    "                    pass\n",
    "            else:\n",
    "                print(gene + ' no results on litvar2 rsid2pmids')\n",
    "                time.sleep(0.8)\n",
    "                pass\n",
    "    else:\n",
    "        print(gene + ' no results on litvar2 gene2pmidcount')\n",
    "        pass\n",
    "\n",
    "    if request_counter > 9000:\n",
    "        dada = 2\n",
    "        #print('Allert! Reaching pubmed request limit')\n",
    "    if request_counter > 9950:\n",
    "        #print('Request limit reached. Wait \\'till tomorrow!')\n",
    "        time_finish = datetime.now()\n",
    "        time_batch = time_finish - time_start\n",
    "        time_batch_str = str(time_batch).split('.')[0]\n",
    "        #print('time batch:', time_batch_str)\n",
    "        #break\n",
    "\n",
    "complete_df = complete_df.reindex(columns=['gene','rsid', 'pmids', 'mesh', 'qualifier', 'major'])\n",
    "complete_df.to_csv(db_path+'/grpm_table_output.csv')\n",
    "\n",
    "complete_nbibtable = complete_nbibtable.reindex(columns=['gene','pubmed_id', 'citation_owner', 'nlm_status', 'last_revision_date', 'electronic_issn', 'linking_issn', 'journal_volume', 'journal_issue', 'publication_date', 'title', 'abstract', 'authors', 'language', 'grants', 'publication_types', 'electronic_publication_date', 'place_of_publication', 'journal_abbreviated', 'journal', 'nlm_journal_id', 'descriptors', 'pmcid', 'keywords', 'conflict_of_interest', 'received_time', 'revised_time', 'accepted_time', 'pubmed_time', 'medline_time', 'entrez_time', 'pii', 'doi', 'publication_status', 'print_issn', 'pages'])\n",
    "complete_nbibtable.to_csv(db_path+'/complete_nbibtable.csv')\n",
    "\n",
    "time_finish = datetime.now()\n",
    "time_batch = time_finish - time_start\n",
    "time_batch_str = str(time_batch).split('.')[0]\n",
    "print('gene batch:', len(genes))\n",
    "print('time batch:', time_batch_str)\n",
    "print('runtime/gene:', time_batch/len(genes))\n",
    "print('request_counter:', request_counter,' (limit: 10.000/day)')\n",
    "gene_counter += len(genes)\n",
    "print('requests/gene:', request_counter/gene_counter)\n",
    "print(time_finish)\n",
    "\n",
    "### notes:\n",
    "# LIMITS PubMed Programming Utilities (PMU)\n",
    "# 10 requests/second\n",
    "# 10,000 requests/day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T10:23:52.966588200Z",
     "start_time": "2024-03-15T10:23:52.845573700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grpm report:\n"
     ]
    },
    {
     "data": {
      "text/plain": "        ncbi_dbsnp lit2_variant lit2_variant_norsid lit2_rsid lit2_rsid_plus1  \\\nTAP2            na          416                  35       363             193   \nPRODH           na          358                  72       262             133   \nMFHAS1          na          612                   7       604             250   \nGNL1            na          153                   6       147              52   \nABCB11          na         1012                 163       726             359   \nWFDC10A         na           29                   0        29              15   \nPCSK2           na          621                  28       579             259   \nGART            na          292                  38       248             100   \nLILRB1          na          581                  27       535             251   \nRPS4Y2          na           23                   1        22               4   \nPOLR1H          na           55                   0        55              38   \nNCR1            na          422                  38       381             183   \nPRSS55          na          235                   1       234              96   \nTIMM22          na           89                  15        71              34   \nMED22           na          153                   1       152              52   \nFCGBP           na         1169                  11      1157             462   \nNOTCH4          na          817                   4       776             360   \n\n        lit1_rsid lit1_rsid_pmid_plus1 lit1_pmid lit1_pmid_pmid_plus1  \\\nTAP2            0                    1         2                    2   \nPRODH           0                    1         9                    9   \nMFHAS1          0                    1         2                    2   \nGNL1            0                    1         2                    2   \nABCB11          0                    1         2                    2   \nWFDC10A         0                    1         4                    4   \nPCSK2           0                    1         4                    4   \nGART            0                    1         5                    5   \nLILRB1          0                    1         2                    2   \nRPS4Y2          0                    1         2                    2   \nPOLR1H          0                    1        23                   23   \nNCR1            0                    1         2                    2   \nPRSS55          0                    1         6                    6   \nTIMM22          0                    1         2                    2   \nMED22           0                    1         3                    3   \nFCGBP           0                    1         3                    3   \nNOTCH4          0                    1         2                    2   \n\n        pubmed_pmid_query  ... pubmed_mesh_qualifier_major pubmed_mesh  \\\nTAP2                    2  ...                          28          26   \nPRODH                   9  ...                          87          66   \nMFHAS1                  2  ...                          36          29   \nGNL1                    2  ...                          29          25   \nABCB11                  2  ...                          18          17   \nWFDC10A                 4  ...                          72          59   \nPCSK2                   4  ...                          51          40   \nGART                    5  ...                          69          53   \nLILRB1                  2  ...                          36          28   \nRPS4Y2                  2  ...                          20          19   \nPOLR1H                 23  ...                         279         194   \nNCR1                    2  ...                          22          19   \nPRSS55                  6  ...                          59          49   \nTIMM22                  2  ...                          30          26   \nMED22                   3  ...                          44          40   \nFCGBP                   3  ...                          52          47   \nNOTCH4                  2  ...                          26          24   \n\n        rsid_pmid10 rsid_pmid50 rsid_pmid100  \\\nTAP2              0           0            0   \nPRODH             0           0            0   \nMFHAS1            0           0            0   \nGNL1              0           0            0   \nABCB11            0           0            0   \nWFDC10A           0           0            0   \nPCSK2             0           0            0   \nGART              0           0            0   \nLILRB1            0           0            0   \nRPS4Y2            0           0            0   \nPOLR1H            1           0            0   \nNCR1              0           0            0   \nPRSS55            0           0            0   \nTIMM22            0           0            0   \nMED22             0           0            0   \nFCGBP             0           0            0   \nNOTCH4            0           0            0   \n\n                                             top10mesh_all    top10rsid_all  \\\nTAP2     ['Adolescent', 'Adult', 'Humans', 'Genome-Wide...    ['rs9501224']   \nPRODH    ['Humans', 'Genome-Wide Association Study', 'G...    ['rs9618419']   \nMFHAS1   ['Humans', 'Adaptation, Physiological', 'Heel'...    ['rs9942753']   \nGNL1     ['Humans', 'Male', 'Isocitrate Dehydrogenase',...    ['rs9468787']   \nABCB11   ['ATP Binding Cassette Transporter, Subfamily ...  ['rs979738325']   \nWFDC10A  ['Humans', 'Young Adult', 'Polymorphism, Singl...   ['rs80157014']   \nPCSK2    ['Humans', 'Genome-Wide Association Study', 'G...     ['rs981662']   \nGART     ['Humans', 'Male', 'Gene Expression Profiling'...    ['rs9636610']   \nLILRB1   ['Animals', 'Cell Line, Tumor', 'Signal Transd...  ['rs995680547']   \nRPS4Y2   ['Humans', 'Male', 'Precision Medicine', 'Poly...  ['rs746235827']   \nPOLR1H   ['Humans', 'Polymorphism, Single Nucleotide', ...    ['rs9295829']   \nNCR1     ['Cell Line, Tumor', 'Humans', 'Analysis of Va...  ['rs994698536']   \nPRSS55   ['Humans', 'Mutation', 'Neoplasms', 'Female', ...  ['rs866683259']   \nTIMM22   ['Adult', 'Polymorphism, Single Nucleotide', '...    ['rs9898238']   \nMED22    ['Humans', 'Female', 'Animals', 'Male', 'Genom...    ['rs9645010']   \nFCGBP    ['Humans', 'Mutation', 'Cell Line, Tumor', 'Ad...  ['rs931113737']   \nNOTCH4   ['Humans', 'Cell Line, Tumor', 'Analysis of Va...  ['rs998603711']   \n\n        pubmed_runtime total_runtime                  time_stamp  \nTAP2           0:00:02       0:00:05  2024-03-15 11:05:29.231491  \nPRODH          0:00:02       0:00:05  2024-03-15 11:05:34.818106  \nMFHAS1         0:00:02       0:00:05  2024-03-15 11:05:40.187241  \nGNL1           0:00:02       0:00:04  2024-03-15 11:05:44.815576  \nABCB11         0:00:02       0:00:05  2024-03-15 11:05:49.994041  \nWFDC10A        0:00:02       0:00:04  2024-03-15 11:05:59.741341  \nPCSK2          0:00:02       0:00:05  2024-03-15 11:06:05.006056  \nGART           0:00:02       0:00:04  2024-03-15 11:06:09.594079  \nLILRB1         0:00:02       0:00:05  2024-03-15 11:06:14.936516  \nRPS4Y2         0:00:02       0:00:05  2024-03-15 11:17:23.046608  \nPOLR1H         0:00:02       0:00:05  2024-03-15 11:17:28.090980  \nNCR1           0:00:02       0:00:05  2024-03-15 11:17:33.681760  \nPRSS55         0:00:02       0:00:04  2024-03-15 11:23:17.835178  \nTIMM22         0:00:02       0:00:04  2024-03-15 11:23:22.283018  \nMED22          0:00:02       0:00:04  2024-03-15 11:23:26.786083  \nFCGBP          0:00:02       0:00:06  2024-03-15 11:23:33.097530  \nNOTCH4         0:00:02       0:00:05  2024-03-15 11:23:38.915557  \n\n[17 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ncbi_dbsnp</th>\n      <th>lit2_variant</th>\n      <th>lit2_variant_norsid</th>\n      <th>lit2_rsid</th>\n      <th>lit2_rsid_plus1</th>\n      <th>lit1_rsid</th>\n      <th>lit1_rsid_pmid_plus1</th>\n      <th>lit1_pmid</th>\n      <th>lit1_pmid_pmid_plus1</th>\n      <th>pubmed_pmid_query</th>\n      <th>...</th>\n      <th>pubmed_mesh_qualifier_major</th>\n      <th>pubmed_mesh</th>\n      <th>rsid_pmid10</th>\n      <th>rsid_pmid50</th>\n      <th>rsid_pmid100</th>\n      <th>top10mesh_all</th>\n      <th>top10rsid_all</th>\n      <th>pubmed_runtime</th>\n      <th>total_runtime</th>\n      <th>time_stamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>TAP2</th>\n      <td>na</td>\n      <td>416</td>\n      <td>35</td>\n      <td>363</td>\n      <td>193</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>28</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Adolescent', 'Adult', 'Humans', 'Genome-Wide...</td>\n      <td>['rs9501224']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:05:29.231491</td>\n    </tr>\n    <tr>\n      <th>PRODH</th>\n      <td>na</td>\n      <td>358</td>\n      <td>72</td>\n      <td>262</td>\n      <td>133</td>\n      <td>0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>9</td>\n      <td>9</td>\n      <td>...</td>\n      <td>87</td>\n      <td>66</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Genome-Wide Association Study', 'G...</td>\n      <td>['rs9618419']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:05:34.818106</td>\n    </tr>\n    <tr>\n      <th>MFHAS1</th>\n      <td>na</td>\n      <td>612</td>\n      <td>7</td>\n      <td>604</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>36</td>\n      <td>29</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Adaptation, Physiological', 'Heel'...</td>\n      <td>['rs9942753']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:05:40.187241</td>\n    </tr>\n    <tr>\n      <th>GNL1</th>\n      <td>na</td>\n      <td>153</td>\n      <td>6</td>\n      <td>147</td>\n      <td>52</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>29</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Male', 'Isocitrate Dehydrogenase',...</td>\n      <td>['rs9468787']</td>\n      <td>0:00:02</td>\n      <td>0:00:04</td>\n      <td>2024-03-15 11:05:44.815576</td>\n    </tr>\n    <tr>\n      <th>ABCB11</th>\n      <td>na</td>\n      <td>1012</td>\n      <td>163</td>\n      <td>726</td>\n      <td>359</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>18</td>\n      <td>17</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['ATP Binding Cassette Transporter, Subfamily ...</td>\n      <td>['rs979738325']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:05:49.994041</td>\n    </tr>\n    <tr>\n      <th>WFDC10A</th>\n      <td>na</td>\n      <td>29</td>\n      <td>0</td>\n      <td>29</td>\n      <td>15</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>72</td>\n      <td>59</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Young Adult', 'Polymorphism, Singl...</td>\n      <td>['rs80157014']</td>\n      <td>0:00:02</td>\n      <td>0:00:04</td>\n      <td>2024-03-15 11:05:59.741341</td>\n    </tr>\n    <tr>\n      <th>PCSK2</th>\n      <td>na</td>\n      <td>621</td>\n      <td>28</td>\n      <td>579</td>\n      <td>259</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>...</td>\n      <td>51</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Genome-Wide Association Study', 'G...</td>\n      <td>['rs981662']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:06:05.006056</td>\n    </tr>\n    <tr>\n      <th>GART</th>\n      <td>na</td>\n      <td>292</td>\n      <td>38</td>\n      <td>248</td>\n      <td>100</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>...</td>\n      <td>69</td>\n      <td>53</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Male', 'Gene Expression Profiling'...</td>\n      <td>['rs9636610']</td>\n      <td>0:00:02</td>\n      <td>0:00:04</td>\n      <td>2024-03-15 11:06:09.594079</td>\n    </tr>\n    <tr>\n      <th>LILRB1</th>\n      <td>na</td>\n      <td>581</td>\n      <td>27</td>\n      <td>535</td>\n      <td>251</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>36</td>\n      <td>28</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Animals', 'Cell Line, Tumor', 'Signal Transd...</td>\n      <td>['rs995680547']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:06:14.936516</td>\n    </tr>\n    <tr>\n      <th>RPS4Y2</th>\n      <td>na</td>\n      <td>23</td>\n      <td>1</td>\n      <td>22</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>20</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Male', 'Precision Medicine', 'Poly...</td>\n      <td>['rs746235827']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:17:23.046608</td>\n    </tr>\n    <tr>\n      <th>POLR1H</th>\n      <td>na</td>\n      <td>55</td>\n      <td>0</td>\n      <td>55</td>\n      <td>38</td>\n      <td>0</td>\n      <td>1</td>\n      <td>23</td>\n      <td>23</td>\n      <td>23</td>\n      <td>...</td>\n      <td>279</td>\n      <td>194</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Polymorphism, Single Nucleotide', ...</td>\n      <td>['rs9295829']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:17:28.090980</td>\n    </tr>\n    <tr>\n      <th>NCR1</th>\n      <td>na</td>\n      <td>422</td>\n      <td>38</td>\n      <td>381</td>\n      <td>183</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>22</td>\n      <td>19</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Cell Line, Tumor', 'Humans', 'Analysis of Va...</td>\n      <td>['rs994698536']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:17:33.681760</td>\n    </tr>\n    <tr>\n      <th>PRSS55</th>\n      <td>na</td>\n      <td>235</td>\n      <td>1</td>\n      <td>234</td>\n      <td>96</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>...</td>\n      <td>59</td>\n      <td>49</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Mutation', 'Neoplasms', 'Female', ...</td>\n      <td>['rs866683259']</td>\n      <td>0:00:02</td>\n      <td>0:00:04</td>\n      <td>2024-03-15 11:23:17.835178</td>\n    </tr>\n    <tr>\n      <th>TIMM22</th>\n      <td>na</td>\n      <td>89</td>\n      <td>15</td>\n      <td>71</td>\n      <td>34</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>30</td>\n      <td>26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Adult', 'Polymorphism, Single Nucleotide', '...</td>\n      <td>['rs9898238']</td>\n      <td>0:00:02</td>\n      <td>0:00:04</td>\n      <td>2024-03-15 11:23:22.283018</td>\n    </tr>\n    <tr>\n      <th>MED22</th>\n      <td>na</td>\n      <td>153</td>\n      <td>1</td>\n      <td>152</td>\n      <td>52</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>44</td>\n      <td>40</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Female', 'Animals', 'Male', 'Genom...</td>\n      <td>['rs9645010']</td>\n      <td>0:00:02</td>\n      <td>0:00:04</td>\n      <td>2024-03-15 11:23:26.786083</td>\n    </tr>\n    <tr>\n      <th>FCGBP</th>\n      <td>na</td>\n      <td>1169</td>\n      <td>11</td>\n      <td>1157</td>\n      <td>462</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>...</td>\n      <td>52</td>\n      <td>47</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Mutation', 'Cell Line, Tumor', 'Ad...</td>\n      <td>['rs931113737']</td>\n      <td>0:00:02</td>\n      <td>0:00:06</td>\n      <td>2024-03-15 11:23:33.097530</td>\n    </tr>\n    <tr>\n      <th>NOTCH4</th>\n      <td>na</td>\n      <td>817</td>\n      <td>4</td>\n      <td>776</td>\n      <td>360</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>26</td>\n      <td>24</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>['Humans', 'Cell Line, Tumor', 'Analysis of Va...</td>\n      <td>['rs998603711']</td>\n      <td>0:00:02</td>\n      <td>0:00:05</td>\n      <td>2024-03-15 11:23:38.915557</td>\n    </tr>\n  </tbody>\n</table>\n<p>17 rows  25 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grpm table genes: 17\n",
      "\n",
      "nbib table:\n"
     ]
    },
    {
     "data": {
      "text/plain": "      gene  pubmed_id citation_owner nlm_status   last_revision_date  \\\n0     TAP2   28425483            NLM    MEDLINE           2023-11-12   \n1     TAP2   26259071            NLM    MEDLINE           2019-04-23   \n0    PRODH   36670122            NLM    MEDLINE           2023-12-07   \n1    PRODH   35449099            NLM    MEDLINE           2022-05-18   \n2    PRODH   27769252            NLM    MEDLINE           2022-12-07   \n..     ...        ...            ...        ...                  ...   \n0    FCGBP   27397505            NLM    MEDLINE  2022-03-18 00:00:00   \n1    FCGBP   32579932            NLM    MEDLINE  2021-12-04 00:00:00   \n2    FCGBP   23042115            NLM    MEDLINE  2022-03-16 00:00:00   \n0   NOTCH4   27397505            NLM    MEDLINE  2022-03-18 00:00:00   \n1   NOTCH4   31253177            NLM    MEDLINE  2020-03-09 00:00:00   \n\n   electronic_issn linking_issn journal_volume journal_issue publication_date  \\\n0        2041-1723    2041-1723              8           NaN      2017 Apr 20   \n1        2041-1723    2041-1723              6           NaN      2015 Aug 10   \n0        2041-1723    2041-1723             14           1.0      2023 Jan 20   \n1        1479-5876    1479-5876             20           1.0      2022 Apr 21   \n2        1471-2490    1471-2490             16           1.0      2016 Oct 21   \n..             ...          ...            ...           ...              ...   \n0        1097-4172    0092-8674            166             3      2016 Jul 28   \n1        2211-1247          NaN             31            12      2020 Jun 23   \n2        1546-1718    1061-4036             44            12         2012 Dec   \n0        1097-4172    0092-8674            166             3      2016 Jul 28   \n1        1756-994X    1756-994X             11             1      2019 Jun 28   \n\n    ...         revised_time        accepted_time          pubmed_time  \\\n0   ...                  NaN           2017-01-27  2017-04-21 06:00:00   \n1   ...                  NaN           2015-07-01  2015-08-11 06:00:00   \n0   ...                  NaN           2022-12-21  2023-01-21 06:00:00   \n1   ...                  NaN           2022-04-03  2022-04-23 06:00:00   \n2   ...                  NaN           2016-10-14  2016-10-23 06:00:00   \n..  ...                  ...                  ...                  ...   \n0   ...  2015-12-23 00:00:00  2016-06-03 00:00:00  2016-07-12 06:00:00   \n1   ...  2020-04-03 00:00:00  2020-06-02 00:00:00  2020-06-25 06:00:00   \n2   ...                  NaN  2012-09-26 00:00:00  2012-10-09 06:00:00   \n0   ...  2015-12-23 00:00:00  2016-06-03 00:00:00  2016-07-12 06:00:00   \n1   ...                  NaN  2019-06-13 00:00:00  2019-06-30 06:00:00   \n\n           medline_time          entrez_time                    pii  \\\n0   2018-11-10 06:00:00  2017-04-21 06:00:00            ncomms14828   \n1   2016-04-28 06:00:00  2015-08-11 06:00:00             ncomms8971   \n0   2023-01-25 06:00:00  2023-01-20 23:15:00                  35724   \n1   2022-04-26 06:00:00  2022-04-22 05:13:00                   3377   \n2   2017-03-03 06:00:00  2016-10-23 06:00:00                    180   \n..                  ...                  ...                    ...   \n0   2016-12-15 06:00:00  2016-07-12 06:00:00  S0092-8674(16)30746-2   \n1   2021-04-29 06:00:00  2020-06-25 06:00:00                 107806   \n2   2013-02-14 06:00:00  2012-10-09 06:00:00                ng.2446   \n0   2016-12-15 06:00:00  2016-07-12 06:00:00  S0092-8674(16)30746-2   \n1   2019-12-28 06:00:00  2019-06-30 06:00:00                    654   \n\n                             doi publication_status print_issn    pages  \n0            10.1038/ncomms14828           epublish        NaN    14828  \n1             10.1038/ncomms8971           epublish        NaN     7971  \n0     10.1038/s41467-022-35724-1           epublish        NaN      342  \n1     10.1186/s12967-022-03377-9           epublish        NaN      181  \n2      10.1186/s12894-016-0180-4           epublish        NaN       62  \n..                           ...                ...        ...      ...  \n0     10.1016/j.cell.2016.06.017           ppublish  0092-8674  740-754  \n1   10.1016/j.celrep.2020.107806           ppublish        NaN   107806  \n2                10.1038/ng.2446           ppublish  1061-4036   1365-9  \n0     10.1016/j.cell.2016.06.017           ppublish  0092-8674  740-754  \n1      10.1186/s13073-019-0654-6           epublish        NaN       42  \n\n[75 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gene</th>\n      <th>pubmed_id</th>\n      <th>citation_owner</th>\n      <th>nlm_status</th>\n      <th>last_revision_date</th>\n      <th>electronic_issn</th>\n      <th>linking_issn</th>\n      <th>journal_volume</th>\n      <th>journal_issue</th>\n      <th>publication_date</th>\n      <th>...</th>\n      <th>revised_time</th>\n      <th>accepted_time</th>\n      <th>pubmed_time</th>\n      <th>medline_time</th>\n      <th>entrez_time</th>\n      <th>pii</th>\n      <th>doi</th>\n      <th>publication_status</th>\n      <th>print_issn</th>\n      <th>pages</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TAP2</td>\n      <td>28425483</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2023-11-12</td>\n      <td>2041-1723</td>\n      <td>2041-1723</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>2017 Apr 20</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2017-01-27</td>\n      <td>2017-04-21 06:00:00</td>\n      <td>2018-11-10 06:00:00</td>\n      <td>2017-04-21 06:00:00</td>\n      <td>ncomms14828</td>\n      <td>10.1038/ncomms14828</td>\n      <td>epublish</td>\n      <td>NaN</td>\n      <td>14828</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TAP2</td>\n      <td>26259071</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2019-04-23</td>\n      <td>2041-1723</td>\n      <td>2041-1723</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>2015 Aug 10</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2015-07-01</td>\n      <td>2015-08-11 06:00:00</td>\n      <td>2016-04-28 06:00:00</td>\n      <td>2015-08-11 06:00:00</td>\n      <td>ncomms8971</td>\n      <td>10.1038/ncomms8971</td>\n      <td>epublish</td>\n      <td>NaN</td>\n      <td>7971</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>PRODH</td>\n      <td>36670122</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2023-12-07</td>\n      <td>2041-1723</td>\n      <td>2041-1723</td>\n      <td>14</td>\n      <td>1.0</td>\n      <td>2023 Jan 20</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2022-12-21</td>\n      <td>2023-01-21 06:00:00</td>\n      <td>2023-01-25 06:00:00</td>\n      <td>2023-01-20 23:15:00</td>\n      <td>35724</td>\n      <td>10.1038/s41467-022-35724-1</td>\n      <td>epublish</td>\n      <td>NaN</td>\n      <td>342</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PRODH</td>\n      <td>35449099</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2022-05-18</td>\n      <td>1479-5876</td>\n      <td>1479-5876</td>\n      <td>20</td>\n      <td>1.0</td>\n      <td>2022 Apr 21</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2022-04-03</td>\n      <td>2022-04-23 06:00:00</td>\n      <td>2022-04-26 06:00:00</td>\n      <td>2022-04-22 05:13:00</td>\n      <td>3377</td>\n      <td>10.1186/s12967-022-03377-9</td>\n      <td>epublish</td>\n      <td>NaN</td>\n      <td>181</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PRODH</td>\n      <td>27769252</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2022-12-07</td>\n      <td>1471-2490</td>\n      <td>1471-2490</td>\n      <td>16</td>\n      <td>1.0</td>\n      <td>2016 Oct 21</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2016-10-14</td>\n      <td>2016-10-23 06:00:00</td>\n      <td>2017-03-03 06:00:00</td>\n      <td>2016-10-23 06:00:00</td>\n      <td>180</td>\n      <td>10.1186/s12894-016-0180-4</td>\n      <td>epublish</td>\n      <td>NaN</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>FCGBP</td>\n      <td>27397505</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2022-03-18 00:00:00</td>\n      <td>1097-4172</td>\n      <td>0092-8674</td>\n      <td>166</td>\n      <td>3</td>\n      <td>2016 Jul 28</td>\n      <td>...</td>\n      <td>2015-12-23 00:00:00</td>\n      <td>2016-06-03 00:00:00</td>\n      <td>2016-07-12 06:00:00</td>\n      <td>2016-12-15 06:00:00</td>\n      <td>2016-07-12 06:00:00</td>\n      <td>S0092-8674(16)30746-2</td>\n      <td>10.1016/j.cell.2016.06.017</td>\n      <td>ppublish</td>\n      <td>0092-8674</td>\n      <td>740-754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FCGBP</td>\n      <td>32579932</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2021-12-04 00:00:00</td>\n      <td>2211-1247</td>\n      <td>NaN</td>\n      <td>31</td>\n      <td>12</td>\n      <td>2020 Jun 23</td>\n      <td>...</td>\n      <td>2020-04-03 00:00:00</td>\n      <td>2020-06-02 00:00:00</td>\n      <td>2020-06-25 06:00:00</td>\n      <td>2021-04-29 06:00:00</td>\n      <td>2020-06-25 06:00:00</td>\n      <td>107806</td>\n      <td>10.1016/j.celrep.2020.107806</td>\n      <td>ppublish</td>\n      <td>NaN</td>\n      <td>107806</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FCGBP</td>\n      <td>23042115</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2022-03-16 00:00:00</td>\n      <td>1546-1718</td>\n      <td>1061-4036</td>\n      <td>44</td>\n      <td>12</td>\n      <td>2012 Dec</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2012-09-26 00:00:00</td>\n      <td>2012-10-09 06:00:00</td>\n      <td>2013-02-14 06:00:00</td>\n      <td>2012-10-09 06:00:00</td>\n      <td>ng.2446</td>\n      <td>10.1038/ng.2446</td>\n      <td>ppublish</td>\n      <td>1061-4036</td>\n      <td>1365-9</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>NOTCH4</td>\n      <td>27397505</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2022-03-18 00:00:00</td>\n      <td>1097-4172</td>\n      <td>0092-8674</td>\n      <td>166</td>\n      <td>3</td>\n      <td>2016 Jul 28</td>\n      <td>...</td>\n      <td>2015-12-23 00:00:00</td>\n      <td>2016-06-03 00:00:00</td>\n      <td>2016-07-12 06:00:00</td>\n      <td>2016-12-15 06:00:00</td>\n      <td>2016-07-12 06:00:00</td>\n      <td>S0092-8674(16)30746-2</td>\n      <td>10.1016/j.cell.2016.06.017</td>\n      <td>ppublish</td>\n      <td>0092-8674</td>\n      <td>740-754</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NOTCH4</td>\n      <td>31253177</td>\n      <td>NLM</td>\n      <td>MEDLINE</td>\n      <td>2020-03-09 00:00:00</td>\n      <td>1756-994X</td>\n      <td>1756-994X</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2019 Jun 28</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>2019-06-13 00:00:00</td>\n      <td>2019-06-30 06:00:00</td>\n      <td>2019-12-28 06:00:00</td>\n      <td>2019-06-30 06:00:00</td>\n      <td>654</td>\n      <td>10.1186/s13073-019-0654-6</td>\n      <td>epublish</td>\n      <td>NaN</td>\n      <td>42</td>\n    </tr>\n  </tbody>\n</table>\n<p>75 rows  36 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('grpm report:')\n",
    "display(pd.read_csv(db_path+'/GRPM_report.csv', index_col=0).T)\n",
    "print('grpm table genes:', len(pd.read_csv(db_path+'/grpm_table_output.csv').gene.drop_duplicates()))\n",
    "\n",
    "print('\\nnbib table:')\n",
    "display(pd.read_csv(db_path+'/complete_nbibtable.csv',index_col=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show saved report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-14T10:52:32.906096400Z",
     "start_time": "2024-03-14T10:52:32.888095Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize GRPM_report.csv\n",
    "GRPM_report = pd.read_csv(db_path+'/GRPM_report.csv', index_col=0).transpose().reset_index().rename(columns={'index':'gene'})\n",
    "\n",
    "repo_int_cols = ['lit2_variant', 'lit2_variant_norsid','lit2_rsid','lit2_rsid_plus1', 'lit1_rsid', 'lit1_rsid_pmid_plus1','lit1_pmid', 'lit1_pmid_pmid_plus1','pubmed_pmid_query',    'nbib_objects', 'nbib_objects_withdescriptors', 'pubmed_pmid', 'pubmed_pmid_withmesh', 'pubmed_pmidmesh','pubmed_mesh_qualifier_major','pubmed_mesh', 'rsid_pmid10','rsid_pmid50', 'rsid_pmid100' ]\n",
    "\n",
    "GRPM_report[repo_int_cols] = GRPM_report[repo_int_cols].astype(int)\n",
    "\n",
    "#display(GRPM_report_less.sort_values(by= 'matching_pmids',ascending=False))\n",
    "GRPM_report.sort_values(by='lit1_pmid',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T10:52:32.892115700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show Bar Graph\n",
    "GRPM_report_sort = GRPM_report.sort_values(by= 'pubmed_pmid',ascending=False)\n",
    "\n",
    "x = GRPM_report_sort.gene.iloc[:40]\n",
    "y = GRPM_report_sort['pubmed_pmid'].iloc[:40]\n",
    "plt.figure(figsize=(4, 8))\n",
    "plt.title('PMIDs in Dataset', loc='center',pad=10)\n",
    "\n",
    "plt.barh(x,y)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tick_params(axis='x', which='both', top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "#plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "plt.ylabel('genes')\n",
    "plt.xlabel('pmid count', position=(0.5, 1.08))\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_label_position('top')\n",
    "#plt.savefig('PMID_filtered.png',dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Code Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging: litvar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T10:52:32.895096Z"
    }
   },
   "outputs": [],
   "source": [
    "# if stucked check 'data' variable:\n",
    "# replace manually malformed lines\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging: nbib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T10:52:32.897093200Z"
    }
   },
   "outputs": [],
   "source": [
    "#NBIB PROBLEM SOLVER---------------------------------\n",
    "# replace malformed lines\n",
    "fullnbib= fullnbib.replace('2007/09/31','2007/09/30') # <= some dates are mispelled in pubmed\n",
    "ref = nbib.read(fullnbib)\n",
    "dfbib = pd.DataFrame(ref)\n",
    "dfbib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBIB PROBLEM SOLVER [History] ---------------------------------\n",
    "with open('nbib report '+gene+'.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(fullnbib)\n",
    "with open('nbib report '+gene+'_FIXED.txt', 'r', encoding='utf-8') as file:\n",
    "    fullnbib = file.read() # --> not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eutils: get study type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T10:52:32.899094600Z"
    }
   },
   "outputs": [],
   "source": [
    "check_and_install_module('biopython')\n",
    "from Bio import Entrez\n",
    "Entrez.email = \"your_email@example.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T10:52:32.901094700Z"
    }
   },
   "outputs": [],
   "source": [
    "### EUTILS GET STUDY TYPE MODULE\n",
    "#https://biopython.org/docs/1.76/api/Bio.Entrez.html\n",
    "def get_study_type(pmids):\n",
    "    Entrez.email = 'your_email@your_domain.com'\n",
    "    handle = Entrez.esummary(db='pubmed', id=','.join(pmids), retmode='xml')\n",
    "    records = Entrez.parse(handle)\n",
    "    study_types = []\n",
    "    for record in records:\n",
    "        article_types = record['PubTypeList']\n",
    "        if 'Randomized Controlled Trial' in article_types:\n",
    "            study_types.append('Randomized Controlled Trial')\n",
    "        elif 'Controlled Clinical Trial' in article_types:\n",
    "            study_types.append('Controlled Clinical Trial')\n",
    "        elif 'Cohort Studies' in article_types:\n",
    "            study_types.append('Cohort Study')\n",
    "        elif 'Case-Control Studies' in article_types:\n",
    "            study_types.append('Case-Control Study')\n",
    "        elif 'Review' in article_types:\n",
    "            study_types.append('Review')\n",
    "        elif 'Clinical Trial' in article_types:\n",
    "            study_types.append('Clinical Trial')\n",
    "        elif 'Meta-Analysis' in article_types:\n",
    "            study_types.append('Meta-Analysis')\n",
    "        elif 'Multicenter Study' in article_types:\n",
    "            study_types.append('Multicenter Study')\n",
    "        else:\n",
    "            study_types.append('Unknown')\n",
    "    return study_types\n",
    "\n",
    "pmidlist = list(pmidmesh['pmids'].drop_duplicates())\n",
    "genepmids_str = list(map(str, pmidlist))\n",
    "study_type = get_study_type(genepmids_str)\n",
    "pmids_studytype = pd.DataFrame(list(zip(genepmids_str, study_type)), columns=[gene + '_PMID', 'study type'])\n",
    "request_counter += 1\n",
    "\n",
    "#study type count:\n",
    "pmids_studytype_count = pmids_studytype.groupby('study type').describe().reset_index()\n",
    "pmids_studytype_count.columns = pmids_studytype_count.columns.to_flat_index()\n",
    "new_column_names = ['study_type', 'pmid-count', 'pmid-unique', 'pmid-top', 'pmid-freq']\n",
    "pmids_studytype_count.columns = new_column_names\n",
    "pmids_studytype_countsort = pmids_studytype_count.sort_values(by='pmid-count', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
